# テストガイドライン

## はじめに
本ガイドラインではmedibaにおけるリリースを伴うテストについて、下記6つの分類に定めます。
不具合の混入を未然に防ぎ　“ 安定した品質を提供 ”　する事を目的としています。

* 1.テスト計画
* 2.単体テスト
* 3.性能試験
* 4.脆弱性試験
* 5.結合テスト
* 6.総合テスト
* 7.障害・監視試験

## 1.テスト計画
開発初期においてマスターテストプランを作成しましょう。
マスターテストプランとは、ソフトウェア開発におけるテスト工程で作成されるべき文書の標準規格であるIEEE829-2008で規定されている文書で、  
対象プロジェクトでのテストがうまくいくようにテスト設計の方法（アプローチ）や考え方をまとめた内容を記載するものです。
マスターテストプランに定義すべき項目を以下に述べます。

### テスト概要
* 対象サービス、対象システムにおいてどのようなテストを行うか全体概要を定義します。

### テスト目的
* テストの実行目的を定義します。
* 単体テスト、結合テスト、総合テストといったテストレベルに対して、機能テスト、性能テスト、負荷テスト、セキュリティテストといったテストタイプごとに定義します。

### テストの対象システムとテストスコープ
* テスト対象システムと、テストレベルごとのテストスコープを定義します。


### テストスケジュール
* テストの目的を達成できるよう、テストレベルごとにテストスケジュールを定義します。

### テスト実行環境
* テストを実行する環境と、デバイス・OS・ブラウザ・ネイティブアプリなどの環境条件を定義します。

### コミュニケーションプラン、ステークホルダー
* 不具合レポート先ツールや実施結果、テスト報告を必要とするメンバーやバグ切り分けメンバー、プロジェクト責任者などを定義します。

### テスト基準
* 開始条件、終了基準、中断基準、追加基準などを定義します。

### テスト成果物
* マスターテストプラン、テスト設計書、テストケース、不具合レポート、テスト報告書などの成果物を定義します。

### テスト実行について
テスト実行において主に意識しておくべき項目を以下に述べます。

#### テストレベルについて
* 開発規模、重要度、難易度、サービスの目的などにより実施するテストレベルや各テストレベルで実施する詳細を定義します。  
* テストレベルとは、単体テスト、結合テスト、総合テストのように、開発プロジェクトにおいて組織的に管理するためのテスト作業の段階を指します。
* medibaでは以下の条件にあてはまる案件は、重要度や難易度の高い開発案件として取り扱います。 テストレベルも複数レベルで実施しましょう。
   * 新規構築サービス、システム
   * 大規模リニューアル
   * 個人情報の取得/表示取り扱いがある案件
   * ポイント機能にかかわる新規開発、改修案件
   * 課金機能にかかわる新規開発、改修がある案件
   * SLA基準が高い案件（ライフメディア、KDDIサービス等）
   * 業務要件、運用要件が複雑で全体要件の難易度が高い案件
   * 新規、既存の開発を伴う広告案件
   * フロントエンドで新規デザイン手法を使った案件
   * 機種依存による表示懸念がある案件
* 下記にテストレベルと対応する実施担当、テスト環境の一覧を示します。
   * 原則として実施担当が該当テストレベルの責務を担うこととします。

| テストレベル   | 実施担当                      | テスト環境                |
| -------------  |-------------------------------|---------------------------|
| 単体テスト     | 開発エンジニア                | 開発環境                  |
| 結合テスト     | 開発エンジニア/品質管理担当者 | 開発環境/ステージング環境 |
| 総合テスト     | サービス担当/品質管理担当者   | ステージング環境/商用環境 |

* 各テストレベルを分割したテスト実施対象条件は下記の通りです。（下記イメージ　詳細条件検討中）

| 開発体制   | KDDIサービスグレード   | 個人情報取扱有無 | 決済・課金・ポイント関連機能有無 | 開発範囲           | 単体テスト実施 | 結合テスト実施 | 総合テスト実施 |
|------------|------------------------|------------------|----------------------------------|--------------------|----------------|----------------|----------------|
| auサービス   | キャリアグレード       | 有               | 有                               | 新規               | ○              | ○              | ○              |
| auサービス   | キャリアグレード       | 有               | 有                               | 追加・改修         | ○              | ○              | ○              |
| auサービス   | キャリアグレード       | 有               | 有                               | 大規模リニューアル | ○              | ○              | ○              |
| auサービス   | キャリアグレード       | 無               | 有                               | 新規               | ○              | ○              | ○              |
| auサービス   | キャリアグレード       | 無               | 有                               | 追加・改修         | ○              | ○              | ○              |
| auサービス   | キャリアグレード       | 無               | 有                               | 大規模リニューアル | ○              | ○              | ○              |
| auサービス   | キャリアグレード       | 有               | 無                               | 新規               | ○              | ○              | ○              |
| auサービス   | キャリアグレード       | 有               | 無                               | 追加・改修         | ○              | ○              | ○              |
| auサービス   | キャリアグレード       | 有               | 無                               | 大規模リニューアル | ○              | ○              | ○              |
| auサービス   | キャリアグレード       | 無               | 無                               | 新規               | ○              | ○              | ○              |
| auサービス   | キャリアグレード       | 無               | 無                               | 追加・改修         | ○              | ○              | ○              |
| auサービス   | キャリアグレード       | 無               | 無                               | 大規模リニューアル | ○              | ○              | ○              |
| auサービス   | 準キャリアグレード     | 有               | 有                               | 新規               | ○              | ○              | ○              |
| auサービス   | インターネットグレード | 有               | 有                               | 新規               | ○              | ○              | ○              |
| mediba自社 | -                      | 有               | 有                               | 新規・追加・改修         | ○              | ○              | ○             |

## 2.単体テスト
単体テストではプログラム単体での仕様どおりの振る舞いであるかを検証します。  
単体テストを書くことは、対象のクラスやメソッドの仕様を動作するプログラムとして記述することで、仕様の明確化と保証をもたらします。  
テストの実施は各種フレームワークがサポートしているテスティングフレームワークを使用して行うことが一般的です。  
テストコードはプロダクトコードと同じリポジトリに管理し、CI環境に組み込んで継続的に自動実行できる状態が望ましいです。  
自動化されたテストが継続して実行できることは、機能拡張やリファクタリングを行ううえで大きな助けになります。  

また後続のテストレベルにおいて検出されるバグの修正コストと比較した場合に、単体テストでの修正コストの方が低いため、単体テスト中に軽微なバグをなくすことができれば、以降のテストでは仕様バグの対応のみに集中できる利点もあります。  

### 単体テストのパターン
下記は単体テストを効果的に行うためのパターンになります。  
参考：[xUnit Patterns.com](http://xunitpatterns.com/)

* 自動化されたテスト
  * テストは繰り返しいつでも実行できる状態にする
* 不安定なテスト
  * テストの実行ごとに結果が一定でない状態は望ましくなく、修正が必要
* ドキュメントとしてのテスト
  * テストケースは最も正確なドキュメントであり、仕様書として読める
* 問題の局所化
  * テスト失敗時に問題を特定しやすいよう、テストが小さな単位で記述する
* 不明瞭なテスト
  * 可読性の低いテストコードはメンテナンス性も低く、テストの質にも影響を与えるため、シンプルで分かりやすく記述する
* 独立したテスト
  * 各テストの実行順序に依存しないこと
    * 独立したテストは追加や変更が容易
    * 独立したテストは分散実行が容易

### 単体テストの観点

#### ホワイトボックステストとブラックボックステストについて
* ホワイトボックステストはコード観点のテスト
* ホワイトボックステストは振る舞い観点のテスト
	* カバレッジ率が高くても、振る舞いに誤りがあればそれはバグである
	* カバレッジを意識せず、不作為にテストしても、テストしていないコードは見つけ辛い
* どちらか片方だけを行っても十分とはいえないことに注意する


#### ホワイトボックステストとは
* ホワイトボックステスト
  * コード中の分や分岐、条件などを実行してバグを見つけるテスト
  * どの文、分岐、条件も1回は実行する必要がある
  * カバレッジ率(網羅率)
	*  テストで実行した文、分岐、条件の割合のこと

#### ホワイトボックステストの指標の分類
##### ステートメントカバレッジ（命令網羅）/ C0
* ソースコード中にある全ステートメント（命令、文）のうち、1回でもテストが実行されたステートメントの割合

##### ブランチカバレッジ（分岐網羅）/ C1
* ソースコード中にある全ブランチ（分岐）のうち、1回でもテストが実行された分岐の割合
  * 分岐で条件が成立したときと不成立のときの両方が実行される必要がある

##### コンディションカバレッジ（条件網羅）/ C2
* 分岐に設定されている条件につき、成立したときと不成立のときの両方が実行された割合
  * 分岐に複数の条件が設定されている場合、各条件毎の実行有無を確認する

#### 各種カバレッジの考え方

```
public function myFunction($type)
{
	if ($type === 'A' || $type === 'B' ) {
		echo "処理1";
	} else {
		echo "処理2";
	}
	
	if ($type === 'C') {
		echo "処理3";
	} 
}
```

* ステートメントカバレッジ（命令網羅）/ C0
  * テストケースは、以下の2つでカバレッジ率100%
    * $type == "A" TRUE（処理1）
    * $type == "C" TRUE（処理2）
* ブランチカバレッジ（分岐網羅）/ C1
  * テストケースは、以下の4つでカバレッジ率100%（2 * 2 = 4通り）
    * $type == "A" or  $type == "B" TRUE, $type == "C" TRUE（無効）
    * $type == "A" or  $type == "B" TRUE, $type == "C" FALSE
    * $type == "A" or  $type == "B" FALSE, $type == "C" TRUE
    * $type == "A" or  $type == "B" FALSE, $type == "C" FALSE
* コンディションカバレッジ（条件網羅）/ C2
  * テストケースは、以下の8つでカバレッジ率100%
  * 1つ目の条件を分解して3つの分岐として捉える（2 ^ 3 = 8通り）
    * $type == "A" TRUE, $type == "B" TRUE, $type == "C" TRUE（無効）
    * $type == "A" TRUE, $type == "B" TRUE, $type == "C" FALSE（無効）
    * $type == "A" TRUE, $type == "B" FALSE, $type == "C" TRUE（無効）
    * $type == "A" TRUE, $type == "B" FALSE, $type == "C" FALSE
    * $type == "A" FALSE, $type == "B" TRUE, $type == "C" TRUE（無効）
    * $type == "A" FALSE, $type == "B" TRUE, $type == "C" FALSE
    * $type == "A" FALSE, $type == "B" FALSE, $type == "C" TRUE
    * $type == "A" FALSE, $type == "B" FALSE, $type == "C" FALSE

#### ブラックボックステスト
* ブラックボックステストとは
  * ある入力に対し、仕様どおりの正しい結果が出力されるかを確認するテスト
  * 入力と結果に着目し、テストの合否を判断する

##### 同値分割法
* プログラムが期待する入力値である「有効同値」とそれ以外の「無効同値」のそれぞれの代表値を用意し、それらを入力値としてて実行結果を確認する方法
  * 有効同値が0以上かつ1000未満の場合、無効同値は0未満かつ1000以上

##### 境界値分析法
* 有効同値と無効同値の境界となる値を入力値としてプログラムを実行し、実行結果を確認する方法
  * 有効同値が0以上かつ1000未満の場合、無効同値は0未満かつ1000以上の場合
    * 境界値は、-1,0,999,1000

## 3.性能試験
要件を満たす性能が出るか、パフォーマンスを確かめるものです。
実際の業務を模した内容や量、密度のテストデータを処理させ単位時間あたりの処理能力や応答時間などを計測し、想定した範囲に収まっているかどうかを確かめます。

### 試験種別
#### 目標性能
##### 検証内容
* ピーク時での性能検証
* 同時アクセス数(瞬間風速)
  * 今後のアクセス数増加も考慮した値で性能要求値を満たしていること
  * 年末年始など、リリース後、特定の日・時間に集中アクセスが想定される場合、その予測アクセス数での性能試験の実施、もしくは、運用での回避策が決まっていること(一時的にサーバーの台数を増やすなど)
* レスポンスタイム
  * 各条件下においてのレスポンスタイムがユーザーアクセスでの要件を満たしていること
    * ツール上ではE2Eを考慮したレスポンスタイムは測定されないため注意する
* トランザクションデータボリューム
  * 向こう2年間のデータ増を考慮したボリュームで
    * ユーザーアクセスでのレスポンス要件を満たしていること
    * バッチ処理での要件を満たしていること(10分サイクルの処理であれば、10分以内に処理が終了するなど)

##### 確認方法
* 訴求時の想定もしくはピーク時間帯トラフィック(平均×集中率)

#### ストレス確認/限界性能
##### 検証内容
* バーストラインの検証
  * 決められた性能要求を満たす検証だけではなく、どこまで耐えられるのか限界値を確認しておくこと

##### 確認方法
* 5req/sec程度あげていく

#### 長時間運転
##### 検証内容
* 安定稼働検証

##### 確認方法
* ピーク時間帯トラフィックを10分以上かけ続ける

### 確認事項
* webサーバのリソース（CPU、メモリ、loadaverages、DiskIO）
* DBのリソース
* Slowクエリ
  * 原則、100ms以上かかるクエリは、理由付きのもの以外はすべてチューニング対象
  * 参考:レスポンスに関するKDDIとのSLAは「平均レスポンスタイムが2秒、最遅4秒」"
* キャッシュヒット率（キャッシュが効く状態と効かない状態で確認すること）
* エラーログ
* 負荷ツールでのレポート　スループット、エラー数

### シナリオ
* PV割合から算出した各ページへのリクエスト数
* 訴求などで集中するページ及び機能

### テストシナリオ作成のポイント
実際の運用を想定し、以下のポイントがシナリオにてフォローできているかを確認すること

* トランザクション種別
  * read,write、複合、それぞれのトランザクション種別に応じたシナリオが用意されていること
    * Getによる特定のURLにアクセスしデータ取得
    * Post/Put/Patchによるデータ作成/更新など
    * Deleteによるデータ削除
    * 利用頻度が低くても、ファイルDLや一覧表示など、特定の負荷が高く想定されるものは検討する
* 負荷のかかる箇所
  * 各リソース、モジュールにかかる負荷状況を想定したシナリオが用意され、以下が確認事項として含まれていること
    * キャッシュ設計
      * キャッシュヒット率、キャッシュ種別（ページ、メモリ、クエリ、CDN）
    * 並列リソースの考慮、DBコネクション数
  * サーバ単体の試験になっておらず、一つのシナリオで計測すべき箇所が明確になっていること
    * キャッシュ機構
    * Webサーバ
    * DB
    * その他（KVSなど）
* 負荷の上昇状況などは想定できていること
  * バーストトラフィックによる瞬間的な負荷の増大など
  * 負荷をかける時間
  * 負荷の上昇速度、傾向
* イベントへの対応
  * 特定のイベント(スマパスの日など)では、UIや導線の変更が発生し、負荷のかかり方やかかる場所が平常時と大きく異なる場合がある。そのような場合は、以下を考慮したシナリオを別に作成し、試験すること
    * 画像数、画像サイズなどページ容量の変動
    * イベント時のみ有効になる動的モジュール
    * 参照されるデータ量、データ種別の違い

### テスト環境の作成
実際の運用を想定した環境になっていること

* サーバリソース
  * CPU,メモリなど、試験用リソースと商用リソースの性能の違いは考慮できていること
* キャッシュ機構
  * HWに依存するキャッシュ機構について、商用と同じ構成となっていること
* レプリケーション
  * 並列稼働するリソースの考慮はできていること
    * レプリケーション、書き込み遅延など
* データベース
  * テストデータ量は商用環境での運用が考慮されたものになっていること
  * 可能な限り商用環境に合わせた環境にすること。
    * データ種別（ファイル、textなど）
    * データ長
    * 個数
    * 1ファイルあたりの容量
    * 全体の容量

## 4.脆弱性試験
脆弱性試験については重要度に応じて行います。

### アプリケーション脆弱性診断
* KDDI社からの「システム構築事前問診票（SOC診断）」を受ける新規構築案件、大規模改修開発案件については、リリース前までに外部のセキュリティ診断専門の会社にて診断を受けること。
   * 外部のセキュリティ診断専門の会社の選定基準は、以下の診断基準を元にツール、マニュアルでの診断を行っている会社とする。
      * 経済産業省基準　IPA基準　安全なウェブサイトの作り方  
        https://www.ipa.go.jp/security/vuln/websecurity.html

* KDDI社からのSOC診断を受けないアプリケーション開発案件は、開発工程の中でZAPにて診断を行い、S-in判定時の判断材料として提出すること。

## 5.結合テスト
結合テストでは互いに関連し合う機能のインタフェースを確認し、結合したシステム全体として正しく動作するかを検証します。

### テスト実施の準備
* 各機能の詳細設計仕様が明確となっており、不明点がないこと
* すべてのプログラムの単体テストが完了していること
* 他システムとの連携がある場合、結合テストにて連携してテストを行うか確定していること
   * 他システムと連携してテストする場合、疎通確認をしていること
   * 他システムと連携してテストしない場合、代わりとなるスタブやドライバーが用意されていること

### テスト設計、観点
* 結合テストで実施するケースは業務フローや画面仕様書、バッチ仕様書などの設計書をもとに下記に記載する観点で作成します。
* ケースに記載する想定結果は、各設計書に記載されている内容と一致している必要があります。
* 作成したテストケースは、開発チームにてレビューされ、ケースの妥当性、不足がないことが確認されている必要があります。

#### 確認観点
* 関連する機能を対象として管理画面、フロント、バッチ、APIなどの一連の機能の流れを確認すること  
  例) 管理画面で登録～登録内容をフロントにAPIで連携～フロントに表示～フロントから登録～登録内容をバッチで処理
* 業務フローから、フローの組み合わせパターンが網羅されていること
* 画面情報などとの内容の整合性、レイアウトや操作性の統一性などを確認すること  
  ただし、フロントのレイアウトの機種ごとの確認は総合テストの対象
* 各機能の入出力バリエーションやデータのバリエーションを洗い出し、すべて網羅されていること
* 一連の機能の流れの中でエラーが発生した場合（DBダウンやサーバ接続不可等）を考慮して、エラーハンドリングが正しいか確認すること
* バッチについては、障害時を考慮してバッチ異常終了→リランの確認を行うこと
* 他システムとの連携がある場合、送受信データの正常、異常データパターンが網羅的に確認されていること
* 他システムとの連携が失敗した場合（ファイルを受け取れない、接続できない）の確認を行うこと

### テスト実行
* 作成したテストケースに沿って実施する
* 障害内容、事象発生手順、想定する結果を開発担当者へ連携する

### テスト終了条件
* すべてのテストケースの消化が完了していること
* 発見された障害の修正が終了し、再テストまで完了していること
* もし、消化できないケースが存在する場合や発見した障害の修正を対応しない場合、責任者に説明し承認が得られていること

## 6.総合テスト

### テスト実施の準備
開発内容または開発による影響を受ける範囲（以下：開発内容）がステークホルダーへ明らかにされており、合意を得ていること。
* 実施可能なスケジュールになっていること。
* スケジュールが変更される場合の基準が定められていること。
* 開発内容が明らかになっていること。
* テストを実施するスコープが明らかになっていること。
* テストを実施する環境が明らかになっていること。
* 検出した障害をどのように報告されるのか明らかになっていること。
* スケジュール変更となる場合の基準が定められていること。
* 改修した開発内容をステークホルダーに共有、承諾されていること。
* 終了となるための基準が制定されていること。
* 作成者が休んだ際、別の開発者が同様の内容を実施出来るようにしていること。
* 開発内容に個人情報が含まれている場合、

### 分析と設計
* 分析と設計作業はテストの目的、スコープを明らかにしその目的に合わせてテストの内容を決める。
* 仕様、動作、構造、構成などの条件に基づいてテストを実施する優先順位を決める。
* 計画したテストケースをレビューし、開発内容に沿っているか、過不足は無いか確認する。
* テストを実施する上で必要なテストデータを確認する。
* 必要なツール、環境を確認する。
* 抽象的なテストスコープから具体的なテスト実行内容を計画を立てる。
* テストが終了となる基準を策定
* 作成した、分析と設計の内容でステークホルダーの承諾を得る。
* 下記は決定しておくべき事項など
   * ステークホルダー：XXXサービス、担当者：YYY
   * 対象端末を選定方法：全端末・利用シェア率の高い端末の80%程度・特定指定端末のみ、など
   * 対応OS／非対応OS：Android
   * 対応端末／非対応端末：Jr端末、特化端末、未対応
   * 動作保障するバージョンの範囲：
   * ブラウザ種別：Chrome5X以上、Safari、Webview
   * 環境：STGはwifiのみ接続可能
   * IP接続：制限有
   * 不具合発見時の報告：バックログ

### 実装と実行
* 必要なテストケースに優先順位をつけて（実行順、テスト手順など）をスクリプトとして仕様化し、テスト環境を整えて実行する。
* 実行手順をベースにテスト環境や、テストデータを作成し、正しく準備されていることを確認する。
* 実行結果の記録をとり、期待する結果を比較する。
* 不具合が確認された場合、再現性が取れるかどうかを確認し、バグとしてチケットを作成して報告する。

### 終了作業
* 事前に定めた終了基準と比較し、実施したテスト内容で十分か追加テストが必要かを決める。
* テスト結果を事前に定めた終了となる基準と比較し、問題ないことを確認すること。
* 次回のリリース、テスト実施、今後のプロジェクトのために、ナレッジをまとめて共有する。

## 7.障害・監視試験

障害発生時において、システムが想定どおりに動作すること、意図しない動作が発生しないこと、などを検証します。  
既に障害復旧方法が定まっている場合、障害時の対応や復旧方法が正しいこと、漏れがないことも確認します。  
テストには障害発生時のエラー検知や、バックアップ／リカバリの確認までを含んでも良いです。  
テスト結果を評価して、障害復旧手順や運用設計に反映させます。  

### テスト内容について

テスト内容は、SLAや障害復旧マニュアルなどをテストベースとして作成します。  
障害発生時において、SLAに沿い、サービスが継続できることを確認します。  
システム構成において各サーバがダウン、性能劣化した状況下での、ユーザ影響を想定したうえで確認内容を検討することが望ましいです。  
そのため、エンドユーザや入稿作業等を行う業務ユーザなどへの影響を考慮したうえで、しかるべき表示や対応がされるかを確認します。  
また障害復旧時のリカバリを行った際におけるユーザ影響も考慮して確認内容を検討しましょう。  
障害発生起因のシステムに与える影響も考慮し、テスト内容を検討しましょう。  

以下、テスト内容の例を記述します。  

* 障害検知のためのテスト
  * ハードウェア各種閾値
  * ミドルウェア、サーバ各種閾値
* サーバが落ちた場合の挙動のテスト
  * KVSが落ちた場合
  * APIサーバが落ちた場合
  * DBサーバが落ちた場合
  * バッチが落ちた場合
  * 対抗先が落ちた場合
* サーバのパフォーマンスが劣化した場合の挙動のテスト
  * KVSのパフォーマンスが劣化した場合
  * APIサーバのパフォーマンスが劣化した場合
  * DBサーバのパフォーマンスが劣化した場合
  * バッチ処理のパフォーマンスが劣化した場合
  * 対抗先のパフォーマンスが劣化した場合
* 確認箇所（復旧時のユーザ行動も想定する）
  * 画面全体
    * エラーページ
    * Sorryページ
    * メンテナンスページ
  * 画面一部（枠内や画像など）
    * エラー
    * フィラー
